<!DOCTYPE html>
<html lang="en">
    <!-- title -->




<!-- keywords -->




<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="Orangele">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Orangele">
    
    <meta name="keywords" content="hexo,hexo-theme,hexo-blog">
    
    <meta name="description" content>
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Maximum Likelihood Estimation, Maximum A Posterior Estimation and Bayesian Estimation · Orangele&#39;s Blog</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href="/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="stylesheet" href="/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href="/assets/favicon.ico">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script">
    <link rel="preload" href="/scripts/main.js" as="script">
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
</head>

    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Orangele&#39;s Blog.</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Maximum Likelihood Estimation, Maximum A Posterior Estimation and Bayesian Estimation</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Orangele's Blog.</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(https://source.unsplash.com/collection/6787891)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Maximum Likelihood Estimation, Maximum A Posterior Estimation and Bayesian Es...
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-tags = "Machine Learning">Machine Learning</a>
    
        <a class="post-tag" href="javascript:void(0);" data-tags = "Statistics">Statistics</a>
    
</div>
                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">1.8k</span>Reading time: <span class="post-count reading-time">11 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2019/09/07</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <blockquote>
<p>The basic problem we study in probability:<br>Given a data generating process, what are the properties of the outcomes?<br>The basic problem of statistical inference is the inverse of probability:<br>Given the outcomes, what can we say about the process that generated the data?</p>
</blockquote>
<p>The definition above concisely tells the difference between probability and statistics.<br><a id="more"></a></p>
<p>In machine learning, we are given the samples and their labels, and want to estimate a model and its parameters which are the most likely to describe the relation between them. Apparently, machine learning problem is a statistic problem. For parameter estimation, there are three common methods usually confusing the machine learning learners: </p>
<ul>
<li>Maximum Likelihood Estimation(MLE) </li>
<li>Maximum A Posterior Estimation(MAP)</li>
<li>Bayesian Estimation(BE)</li>
</ul>
<p>In this article I’m going to give a gentle explanation on these three concepts and show how they differ from each others. </p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>First, let’s see some background knowledge.</p>
<h3 id="Bayes’-Theorem"><a href="#Bayes’-Theorem" class="headerlink" title="Bayes’ Theorem"></a>Bayes’ Theorem</h3><p>In probability theory and statistics, Bayes’ theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event. It is like this:</p>
<script type="math/tex; mode=display">P(A|B) = \frac{P(B|A)*P(A)}{P(B)}</script><ul>
<li>$P(A|B)$ is a conditional probability, and also called <strong>posterior probability</strong>. It means the probability of event A occuring given that B is true.</li>
<li>$P(B|A)$ is also a <strong>conditional probability</strong>: the probability of event B occuring given that A is true.</li>
<li>$P(A)$ and $P(B)$ are the probability of observing A and B independently of each other. Thay are also called marginal probability or <strong>prior probability</strong>.</li>
</ul>
<h3 id="Probability-Function-amp-Likelihood-Function"><a href="#Probability-Function-amp-Likelihood-Function" class="headerlink" title="Probability Function &amp; Likelihood Function"></a>Probability Function &amp; Likelihood Function</h3><p>For the function $P(x|\theta)$, we can view it in two aspects:</p>
<ul>
<li>If $\theta$ is known and invariable and $x$ is variable, $P(x|\theta)$ is a probability function which represents the probability of observing different $x$ under a fixed $\theta$.</li>
<li>If $x$ is known invariable and $\theta$ is variable, then $P(x|\theta)$ is called a likelihood function which represents the probability of observing a specific $x$ under different $\theta$. It can also be written as $L(\theta|x)$.</li>
</ul>
<h3 id="Conjugate-Prior-Distributions"><a href="#Conjugate-Prior-Distributions" class="headerlink" title="Conjugate Prior Distributions"></a>Conjugate Prior Distributions</h3><p>In Bayesian probability theory, if the posterior distributions p are in the same family as the prior probability distribution p, the prior and posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function.</p>
<p>Here are some common conjugate prior distributions:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Distribution</th>
<th>Parameter</th>
<th>Conjugate prior </th>
</tr>
</thead>
<tbody>
<tr>
<td>Binomial</td>
<td>Probability</td>
<td>Beta</td>
</tr>
<tr>
<td>Polynomial</td>
<td>Probability</td>
<td>Dirichlet</td>
</tr>
<tr>
<td>Poisson</td>
<td>Mean</td>
<td>Gamma</td>
</tr>
<tr>
<td>Exponential</td>
<td>Inverse of mean</td>
<td>Gamma</td>
</tr>
<tr>
<td>Gaussian</td>
<td>Mean</td>
<td>Gaussian</td>
</tr>
<tr>
<td>Gaussian</td>
<td>Variance</td>
<td>Inverse-gamma</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Beta-Distribution"><a href="#Beta-Distribution" class="headerlink" title="Beta Distribution"></a>Beta Distribution</h3><p>In probability theory and statistics, the beta distribution is a family of continuous probability distributions defined on the interval [0, 1] parametrized by two positive shape parameters, denoted by $\alpha$ and $\beta$. Its probability density function is:</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(x;\alpha, \beta)&=\frac{x^{\alpha-1}(1-x)^{\beta -1}}{\int^{1}_{0}u^{\alpha-1}(1-u)^{\beta-1}du} \\
&= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1} \\
&= \frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}
\end{aligned}</script><p>A random variable $X$ beta-distributied with $\alpha$ and $\beta$ is denoted by: $X \sim Beta(\alpha,\beta)$</p>
<h2 id="A-Typical-Example"><a href="#A-Typical-Example" class="headerlink" title="A Typical Example"></a>A Typical Example</h2><p>Here is a common and basic example for studying such statistic problems. Let’s assume we have a coin, and we what to estimate the probability $\theta$ for the front side showing in a coin tossing game. We have done 10 experiments, in which front side showed 6 times and back side showed 4 times. We record the results as: </p>
<script type="math/tex; mode=display">X = x_{1}, x_{2},..., x_{10} = 1, 0 ,1 ,1 ,0 ,0 ,0 ,1 ,1 ,1</script><h2 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum Likelihood Estimation"></a>Maximum Likelihood Estimation</h2><p>MLE is a method trying to find the parameters which maximize the probability of the observed data occuring. For an independently and identically distributed sample set, its likelihood function is:</p>
<script type="math/tex; mode=display">L(X|\theta)= \prod_{n}^{i=0} P(x_{i}|\theta)</script><p>More specifically, for our coin tossing example, it is:</p>
<script type="math/tex; mode=display">L(X|\theta)= \theta^6(1-\theta)^4</script><p>By solving $\frac{\partial L(X|\theta)}{\partial \theta} =0$, we can get the $\hat\theta$ we want.</p>
<p>To make it easier to solve, we can convert the likelihood function to log-likelihood function: </p>
<script type="math/tex; mode=display">l(X|\theta)=logL(X|\theta)=6log(\theta)+4\log(1-\theta)</script><p>Then by solving $\frac{\partial l(X|\theta)}{\partial \theta} =0$ we can get $\hat\theta=0.6$. The reason for using log is that log doesn’t change the convex property of the funtion.</p>
<p>However, you may not believe the result because we all know that the probability should be 0.5! But wait, we have no evidence to show that the coin is a totally normal one. Maybe it is not with uniform density? The only TRUTH we have is the experiment result. But now the result is in conflict with our common BELIEF. So, that’s why we need MAP.</p>
<h2 id="Maximum-A-Posteriori-Estimation"><a href="#Maximum-A-Posteriori-Estimation" class="headerlink" title="Maximum A Posteriori Estimation"></a>Maximum A Posteriori Estimation</h2><p>Instead of $P(X|\theta)$, the cost function MAP wants to maximize is:  <script type="math/tex">P(X|\theta)P(\theta)</script>.<br>In MAP, $\theta$ is supposed to be a random variable and obey some distribution. This distribution is a prior distribution, which comes from some assumption or our experience. By maximizing $P(X|\theta)P(\theta)$, we do not only consider the likelihood function $P(X|\theta)$, but also want to increase the probability of the apparence of $\theta$ itself. It is somehow similar to the concept of regularization in machine learning. What is different is that in regularization the regular term is added, but here it is multiplied. </p>
<p>If we transform the cost function $P(X|\theta)P(\theta)$ into  $\frac{P(X|\theta)P(\theta)}{P(X)}$, where $P(X)$ is a constant value (got from samples), we can find based on Bayes’ therom $\frac{P(X|\theta)P(\theta)}{P(X)}$ is actually $P(\theta|X)$, which is the posterior probability of $\theta$. This is why we call the method Maximum A Posteriori Estimation.</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(\theta|X)&= \frac{P(X|\theta)P(\theta)}{P(X)} \propto P(X|\theta)P(\theta)\\
arg\,\max_{\theta}P(\theta|X)&=arg\,\max_{\theta}P(X|\theta)P(\theta)
\end{aligned}</script><p>In our example of tossing coin, we know the probability of $\theta=0.5$ is very high, thus lets assume that $P(\theta)$ is a Gaussian function with mean as 0.5 and variance as 0.1:</p>
<script type="math/tex; mode=display">
P(\theta)= \frac{1}{10\sqrt{2\pi}}e^{-50(\theta-0.5)^2}</script><p>As $P(X|\theta)=\theta^6(1-\theta)^4$, we can get:</p>
<script type="math/tex; mode=display">
\begin{aligned}
P&(X|\theta)P(\theta)=\theta^6(1-\theta)^4\frac{1}{10\sqrt{2\pi}}e^{-50(\theta-0.5)^2}\\
log(P(X|\theta)P(\theta))&=6log\theta +4log(1-\theta)+log(\frac{1}{10\sqrt{2\pi}})-50(\theta-0.5)^2
\end{aligned}</script><p>Solving $\frac{\partial log(P(X|\theta)P(\theta))}{\partial\theta}=0$, we can get $\hat\theta \approx 0.529$.</p>
<p>Now the result seems better, but we need to notice that if we assume $P(\theta)\sim N(0.6,0.1)$, $\hat\theta$ will be 0.6, and if we assume $P(\theta)\sim Beta(3,3)$, $\hat\theta$ will approximately be 0.57. This shows, in MAP a resonable prior distribution is the key factor for a good estimation. </p>
<p>Since after introducing the prior distribution uncertainty increases a lot for the choice of $\theta$, is there any way to estimite the possible distribution of $\theta$ instead of exact value? Yes, that is what Bayesian estimation does.</p>
<h2 id="Bayesian-Estimation"><a href="#Bayesian-Estimation" class="headerlink" title="Bayesian Estimation"></a>Bayesian Estimation</h2><p>Bayasian estimation is a further extension of MAP, where the distribution of parameter $\theta$ is estimated. In BE, $P(X)$ can not be ignored as in MAP. As $X$ is known, the distribution of $\theta$ is $P(\theta|X)$. By Bayes’ formula:</p>
<script type="math/tex; mode=display">
P(\theta|X)= \frac{P(X|\theta)P(\theta)}{P(X)}</script><p>With continuous random variables $\theta$, $P(X)= \int_{\Theta}P(X|\theta)P(\theta)d\theta$. And Bayes’ formula becomes:</p>
<script type="math/tex; mode=display">
P(\theta|X)=\frac {P(X|\theta)P(\theta)} {\int_{\Theta}P(X|\theta)P(\theta)d\theta}</script><p>The calculation of BE really depends on a suitable choice of $P(\theta)$. For our coin tossing example, we can choose conjugate prior distribution. The conjugate prior distribution for the bionomial distrobution is Beta distribution, so we can assume $P(\theta) \sim Beta(\alpha, \beta)$. The probability density formula for Beta distribution is:</p>
<script type="math/tex; mode=display">f(x;\alpha,\beta)=\frac {1} {B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}</script><p>So, the Bayes’ formula becomes:</p>
<script type="math/tex; mode=display">
\begin{aligned} P(\theta|X)&=\frac {P(X|\theta)P(\theta)} {\int_{\Theta}P(X|\theta)P(\theta)d\theta} \\ &=\frac {\theta^6(1-\theta)^4 \frac {\theta^{\alpha-1}(1-\theta)^{\beta-1}} {B(\alpha,\beta)} } {\int_{\Theta}\theta^6(1-\theta)^4 \frac {\theta^{\alpha-1}(1-\theta)^{\beta-1}} {B(\alpha,\beta)}d\theta} \\&=\frac {\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}} {\int_{\Theta}\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}d\theta} \\ &=\frac {\theta^{\alpha+6-1}(1-\theta)^{\beta+4-1}} {B(\alpha+6-1,\beta+4-1)} \\&=Beta(\theta|\alpha+6,\beta+4)\end{aligned}</script><p>$Beta(\theta|\alpha+6,\beta+4)$ is the result distribution of BE.</p>
<p>If the result distribution has a infinite mean, we can use the expectation as an estimate for $theta$. For example, if $\alpha=3, \beta=3$, by the expectation formula for Beta distribution $E(\theta)=\frac {\alpha} {\alpha+\beta}$, we can get:</p>
<script type="math/tex; mode=display">
\hat{\theta}=\int_{\Theta} \theta P(\theta|X)d\theta=E(\theta)=\frac {\alpha} {\alpha+\beta}=\frac {9} {9+7}=0.5625</script><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>From MLE, MAP to BE, the infomation used is increasing. MLE and MAP both try to find a certain value of $\theta$ to maximize their cost funtion, while BE try to get a distribution of $\theta$. In MLE, we don’t consider the prior distribution of $\theta$, while in MAP and BE we do. In MAP, we  have to assume a certain distribution for $\theta$, but in BE we make use of conjugate prior distribution.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>MLE</th>
<th>MAP</th>
<th>BE</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\hat{\theta}$</td>
<td>certain value</td>
<td>certain value</td>
<td>distribution</td>
</tr>
<tr>
<td>$f$</td>
<td>$P(X\mid \theta)$</td>
<td>$P(X\mid \theta)P(\theta)$</td>
<td>$\frac {P(X\mid \theta)P(\theta)}{P(X)}$</td>
</tr>
<tr>
<td>$P(\theta)$</td>
<td>uniform distribution</td>
<td>any reasonable<br>prior distribution</td>
<td>conjugate<br> prior distribution</td>
</tr>
</tbody>
</table>
</div>
<p>MLE is simple and works well on a lot of random samples, but heavily biases to small set of samples. Solutions for MAP and especially for BE are more complicated, but they are less biased if they have a good prior assumption. </p>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>Author：<a href="https://orangelle.github.io">Orangele</a>
            <p>原文链接：<a href="https://orangelle.github.io/2019/09/07/MLE,MAP,BE/">https://orangelle.github.io/2019/09/07/MLE,MAP,BE/</a>
            <p>发表日期：<a href="https://orangelle.github.io/2019/09/07/MLE,MAP,BE/">September 7th 2019, 2:14:18 am</a>
            <p>更新日期：<a href="https://orangelle.github.io/2019/09/07/MLE,MAP,BE/">December 7th 2019, 2:23:58 am</a>
            <p>版权声明：</p>
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2019/12/07/Some-tips-on-tensorflow-2-0/" title= "Some Tips on Tensorflow 2.0">
                    <div class="nextTitle">Some Tips on Tensorflow 2.0</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2019/07/09/Pratical_IO_for_C++/" title= "Practical IO for C++">
                    <div class="prevTitle">Practical IO for C++</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:raku.lxm@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="https://github.com/orangelle" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Background"><span class="toc-number">1.</span> <span class="toc-text">Background</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Bayes’-Theorem"><span class="toc-number">1.1.</span> <span class="toc-text">Bayes’ Theorem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Probability-Function-amp-Likelihood-Function"><span class="toc-number">1.2.</span> <span class="toc-text">Probability Function &amp; Likelihood Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conjugate-Prior-Distributions"><span class="toc-number">1.3.</span> <span class="toc-text">Conjugate Prior Distributions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Beta-Distribution"><span class="toc-number">1.4.</span> <span class="toc-text">Beta Distribution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-Typical-Example"><span class="toc-number">2.</span> <span class="toc-text">A Typical Example</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maximum-Likelihood-Estimation"><span class="toc-number">3.</span> <span class="toc-text">Maximum Likelihood Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maximum-A-Posteriori-Estimation"><span class="toc-number">4.</span> <span class="toc-text">Maximum A Posteriori Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bayesian-Estimation"><span class="toc-number">5.</span> <span class="toc-text">Bayesian Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 4
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2019 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/07</span><a class="archive-post-title" href= "/2019/12/07/Some-tips-on-tensorflow-2-0/" >Some Tips on Tensorflow 2.0</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/07</span><a class="archive-post-title" href= "/2019/12/07/Differences-of-dot-matmul-multiply-outer-in-numpy/" >Differences of dot(), matmul(), multiply(), outer(), *, @ in numpy</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/07</span><a class="archive-post-title" href= "/2019/09/07/MLE,MAP,BE/" >Maximum Likelihood Estimation, Maximum A Posterior Estimation and Bayesian Estimation</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/09</span><a class="archive-post-title" href= "/2019/07/09/Pratical_IO_for_C++/" >Practical IO for C++</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="Numpy"><span class="iconfont-archer">&#xe606;</span>Numpy</span>
    
        <span class="sidebar-tag-name" data-tags="C++"><span class="iconfont-archer">&#xe606;</span>C++</span>
    
        <span class="sidebar-tag-name" data-tags="Machine Learning"><span class="iconfont-archer">&#xe606;</span>Machine Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Statistics"><span class="iconfont-archer">&#xe606;</span>Statistics</span>
    
        <span class="sidebar-tag-name" data-tags="Tensorflow"><span class="iconfont-archer">&#xe606;</span>Tensorflow</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Coding"><span class="iconfont-archer">&#xe60a;</span>Coding</span>
    
        <span class="sidebar-category-name" data-categories="Theory"><span class="iconfont-archer">&#xe60a;</span>Theory</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "Orangele"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script>    
     
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>


